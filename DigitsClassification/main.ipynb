{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as mplt\n",
    "import math\n",
    "\n",
    "from metrics import accuracy_score, RMS_error, crossEntropy_error, confusion_matrix\n",
    "\n",
    "from LogisticRegression import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "def loadMNISTData():\n",
    "\timport pickle\n",
    "\timport gzip\n",
    "\tfilename = 'mnist.pkl.gz'\n",
    "\tf = gzip.open(filename, 'rb')\n",
    "\ttraining_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "\tf.close()\n",
    "\treturn training_data, validation_data, test_data\n",
    "\n",
    "def loadUSPSData():\n",
    "\tfrom PIL import Image\n",
    "\timport os\n",
    "\timport numpy as np\n",
    "\tUSPSMat  = []\n",
    "\tUSPSTar  = []\n",
    "\tcurPath  = 'USPSdata/Numerals'\n",
    "\tsavedImg = []\n",
    "\tfor j in range(0,10):\n",
    "\t    curFolderPath = curPath + '/' + str(j)\n",
    "\t    imgs =  os.listdir(curFolderPath)\n",
    "\t    for img in imgs:\n",
    "\t        curImg = curFolderPath + '/' + img\n",
    "\t        if curImg[-3:] == 'png':\n",
    "\t            img = Image.open(curImg,'r')\n",
    "\t            img = img.resize((28, 28))\n",
    "\t            savedImg = img\n",
    "\t            imgdata = (255-np.array(img.getdata()))/255\n",
    "\t            USPSMat.append(imgdata)\n",
    "\t            USPSTar.append(j)\n",
    "\treturn np.array(USPSMat), np.array(USPSTar)\n",
    "\n",
    "MNIST_training, MNIST_validation, MNIST_testing = loadMNISTData()\n",
    "MNIST_training_X = MNIST_training[0]\n",
    "MNIST_training_T0 = MNIST_training[1]\n",
    "MNIST_validation_X = MNIST_validation[0]\n",
    "MNIST_validation_T0 = MNIST_validation[1]\n",
    "MNIST_testing_X = MNIST_testing[0]\n",
    "MNIST_testing_T0 = MNIST_testing[1]\n",
    "MNIST_training_T = np.array(pd.get_dummies(pd.Series(MNIST_training_T0)))\n",
    "MNIST_validation_T = np.array(pd.get_dummies(pd.Series(MNIST_validation_T0)))\n",
    "MNIST_testing_T = np.array(pd.get_dummies(pd.Series(MNIST_testing_T0)))\n",
    "USPS_X, USPS_T0 = loadUSPSData()\n",
    "USPS_T = np.array(pd.get_dummies(pd.Series(USPS_T0)))\n",
    "\n",
    "def plotGraphs(data, plotName):\n",
    "\tfig, ax = mplt.subplots()\n",
    "\tax.plot(data)\n",
    "\tfig.savefig(plotName+\".jpg\", dpi=fig.dpi)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "lr = 0.005\n",
    "epochs = 1\n",
    "batchSize = 100\n",
    "\n",
    "LogRegressor = LogisticRegression()\n",
    "LogRegressor.fit( np.transpose(MNIST_training_X), np.transpose(MNIST_training_T), lr, epochs, batchSize)\n",
    "plotGraphs(LogRegressor.training_error, \"LogRegressor_training_error\")\n",
    "plotGraphs(LogRegressor.training_accuracy, \"LogRegressor_training_accuracy\")\n",
    "MNIST_training_Err = LogRegressor.training_error[len(LogRegressor.training_error)-1]\n",
    "MNIST_training_AS = LogRegressor.training_accuracy[len(LogRegressor.training_accuracy)-1]\n",
    "print(\"MNIST_training_Err = \"+str(MNIST_training_Err))\n",
    "print(\"MNIST_training_AS = \"+str(MNIST_training_AS))\n",
    "\n",
    "MNIST_validation_Y =  LogRegressor.predict( np.transpose(MNIST_validation_X) )\n",
    "MNIST_validation_Y = np.transpose(MNIST_validation_Y)\n",
    "MNIST_validation_Err = crossEntropy_error( MNIST_validation_T, MNIST_validation_Y )\n",
    "MNIST_validation_Y = LogRegressor.classificationPredict( np.transpose(MNIST_validation_Y) )\n",
    "MNIST_validation_Y = np.transpose(MNIST_validation_Y)\n",
    "MNIST_validation_AS = accuracy_score( MNIST_validation_T, MNIST_validation_Y )\n",
    "print(\"MNIST_validation_Err = \"+str(MNIST_validation_Err))\n",
    "print(\"MNIST_validation_AS = \"+str(MNIST_validation_AS))\n",
    "\n",
    "MNIST_testing_Y = LogRegressor.predict( np.transpose(MNIST_testing_X) )\n",
    "MNIST_testing_Y = np.transpose(MNIST_testing_Y)\n",
    "MNIST_testing_Err = crossEntropy_error( MNIST_testing_T, MNIST_testing_Y )\n",
    "MNIST_testing_Y = LogRegressor.classificationPredict( np.transpose(MNIST_testing_Y) )\n",
    "MNIST_testing_Y = np.transpose(MNIST_testing_Y)\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T, MNIST_testing_Y )\n",
    "print(\"MNIST_testing_Err = \"+str(MNIST_testing_Err))\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = LogRegressor.predict( np.transpose(USPS_X) )\n",
    "USPS_Y = np.transpose(USPS_Y)\n",
    "USPS_Err = crossEntropy_error( USPS_T, USPS_Y )\n",
    "USPS_Y = LogRegressor.classificationPredict( np.transpose(USPS_Y) )\n",
    "USPS_Y = np.transpose(USPS_Y)\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T, USPS_Y )\n",
    "print(\"USPS_Err = \"+str(USPS_Err))\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))\n",
    "MNIST_Y1 = MNIST_testing_Y\n",
    "USPS_Y1 = USPS_Y\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"SVC:\")\n",
    "kernel = \"linear\"\n",
    "gamma = 1\n",
    "\n",
    "svc = SVC(kernel=kernel, gamma=gamma)\n",
    "svc.fit( MNIST_training_X[:500], MNIST_training_T0[:500] )\n",
    "\n",
    "MNIST_training_Y = svc.predict( MNIST_training_X )\n",
    "MNIST_training_Err = RMS_error( MNIST_training_T0, MNIST_training_Y )\n",
    "MNIST_training_AS = accuracy_score( MNIST_training_T0, MNIST_training_Y )\n",
    "print(\"MNIST_training_Err = \"+str(MNIST_training_Err))\n",
    "print(\"MNIST_training_AS = \"+str(MNIST_training_AS))\n",
    "\n",
    "MNIST_validation_Y = svc.predict( MNIST_validation_X )\n",
    "MNIST_validation_Err = RMS_error( MNIST_validation_T0, MNIST_validation_Y )\n",
    "MNIST_validation_AS = accuracy_score( MNIST_validation_T0, MNIST_validation_Y )\n",
    "print(\"MNIST_validation_Err = \"+str(MNIST_validation_Err))\n",
    "print(\"MNIST_validation_AS = \"+str(MNIST_validation_AS))\n",
    "\n",
    "MNIST_testing_Y = svc.predict( MNIST_testing_X )\n",
    "MNIST_testing_Err = RMS_error( MNIST_testing_T0, MNIST_testing_Y )\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T0, MNIST_testing_Y )\n",
    "print(\"MNIST_testing_Err = \"+str(MNIST_testing_Err))\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = svc.predict( USPS_X )\n",
    "USPS_Err = RMS_error( USPS_T0, USPS_Y )\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T0, USPS_Y )\n",
    "print(\"USPS_Err = \"+str(USPS_Err))\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))\n",
    "MNIST_Y2 = np.array(pd.get_dummies(pd.Series(MNIST_testing_Y))) \n",
    "USPS_Y2 = np.array(pd.get_dummies(pd.Series(USPS_Y))) \n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"RF:\")\n",
    "n_estimators = 5\n",
    "criterion = \"gini\"\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion)\n",
    "rf.fit( MNIST_training_X, MNIST_training_T )\n",
    "\n",
    "MNIST_training_Y = rf.predict( MNIST_training_X )\n",
    "MNIST_training_Err = RMS_error( MNIST_training_T, MNIST_training_Y )\n",
    "MNIST_training_AS = accuracy_score( MNIST_training_T, MNIST_training_Y )\n",
    "print(\"MNIST_training_Err = \"+str(MNIST_training_Err))\n",
    "print(\"MNIST_training_AS = \"+str(MNIST_training_AS))\n",
    "\n",
    "MNIST_validation_Y = rf.predict( MNIST_validation_X )\n",
    "MNIST_validation_Err = RMS_error( MNIST_validation_T, MNIST_validation_Y )\n",
    "MNIST_validation_AS = accuracy_score( MNIST_validation_T, MNIST_validation_Y )\n",
    "print(\"MNIST_validation_Err = \"+str(MNIST_validation_Err))\n",
    "print(\"MNIST_validation_AS = \"+str(MNIST_validation_AS))\n",
    "\n",
    "MNIST_testing_Y = rf.predict( MNIST_testing_X )\n",
    "MNIST_testing_Err = RMS_error( MNIST_testing_T, MNIST_testing_Y )\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T, MNIST_testing_Y )\n",
    "print(\"MNIST_testing_Err = \"+str(MNIST_testing_Err))\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = rf.predict( USPS_X )\n",
    "USPS_Err = RMS_error( USPS_T, USPS_Y )\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T, USPS_Y )\n",
    "print(\"USPS_Err = \"+str(USPS_Err))\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))\n",
    "MNIST_Y3 = MNIST_testing_Y\n",
    "USPS_Y3 = USPS_Y\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "def recreateImages(concatenatedImgs):\n",
    "\tinput_size = len(concatenatedImgs[0])\n",
    "\top = []\n",
    "\tfor concatenatedImg in concatenatedImgs:\n",
    "\t\top.append( np.resize(concatenatedImg, ( (int)(math.sqrt(input_size)), (int)(math.sqrt(input_size)), 1 )) )\n",
    "\treturn np.array(op)\n",
    "    \n",
    "print(\"NN:\")\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "#DNN CODE-\n",
    "'''\n",
    "lr = 0.1\n",
    "decay = 1e-6\n",
    "momentum= 0.3\n",
    "first_layer_number_of_nodes = 500\n",
    "second_layer_number_of_nodes = 500\n",
    "DNN = Sequential()\n",
    "DNN.add(Dense(first_layer_number_of_nodes, input_dim=input_size))\n",
    "DNN.add(Activation(\"relu\"))\n",
    "DNN.add(Dropout(0.1))\n",
    "DNN.add(Dense(second_layer_number_of_nodes))\n",
    "DNN.add(Activation(\"relu\"))\n",
    "DNN.add(Dropout(0.1))\n",
    "DNN.add(Dense(output_size))\n",
    "DNN.add(Activation(\"softmax\"))\n",
    "opt = optimizers.SGD(lr=lr,decay=decay,momentum=momentum,nesterov=True)\n",
    "DNN.compile(optimizer=opt, loss=\"mean_squared_error\", metrics=['accuracy'])\n",
    "\n",
    "numOfEpochs = 25\n",
    "modelBatchSize = 200 \n",
    "tbBatchSize = 32\n",
    "earlyPatience = 100\n",
    "tb = TensorBoard(log_dir='logs', batch_size=tbBatchSize, write_graph= True)\n",
    "es = EarlyStopping(monitor='val_loss', verbose=0, patience=earlyPatience, mode='min')\n",
    "history = DNN.fit( MNIST_training_X, MNIST_training_T, validation_data=(MNIST_validation_X, MNIST_validation_T), epochs=numOfEpochs, batch_size=modelBatchSize, verbose=0, callbacks = [tb, es])\n",
    "\n",
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n",
    "\n",
    "MNIST_training_Err = history.history['loss'][len(history.history['loss'])-1]\n",
    "MNIST_training_AS = history.history['acc'][len(history.history['acc'])-1] * 100\n",
    "print(\"MNIST_training_Err = \"+str(MNIST_training_Err))\n",
    "print(\"MNIST_training_AS = \"+str(MNIST_training_AS))\n",
    "\n",
    "MNIST_validation_Err = history.history['val_loss'][len(history.history['val_loss'])-1]\n",
    "MNIST_validation_AS = history.history['acc'][len(history.history['acc'])-1] * 100\n",
    "print(\"MNIST_validation_Err = \"+str(MNIST_validation_Err))\n",
    "print(\"MNIST_validation_AS = \"+str(MNIST_validation_AS))\n",
    "\n",
    "MNIST_testing_Y = DNN.predict( MNIST_testing_X )\n",
    "MNIST_testing_Err = RMS_error( MNIST_testing_T, MNIST_testing_Y )\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T, MNIST_testing_Y )\n",
    "print(\"MNIST_testing_Err = \"+str(MNIST_testing_Err))\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = DNN.predict( USPS_X )\n",
    "USPS_Err = RMS_error( USPS_T, USPS_Y )\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T, USPS_Y )\n",
    "print(\"USPS_Err = \"+str(USPS_Err))\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))\n",
    "MNIST_Y4 = MNIST_testing_Y\n",
    "USPS_Y4 = USPS_Y\n",
    "print()\n",
    "print()\n",
    "\n",
    "'''\n",
    "#CNN CODE-\n",
    "lr = 0.1\n",
    "decay = 1e-6\n",
    "momentum= 0.3\n",
    "inputShape = ((int)(math.sqrt(input_size)), (int)(math.sqrt(input_size)), 1)\n",
    "chanDim = 1\n",
    "CNN = Sequential()\n",
    "# CONV => RELU => POOL layer set\n",
    "CNN.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "CNN.add(Activation(\"relu\"))\n",
    "CNN.add(BatchNormalization(axis=chanDim))\n",
    "CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN.add(Dropout(0.25))\n",
    "# (CONV => RELU) * 2 => POOL layer set\n",
    "CNN.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "CNN.add(Activation(\"relu\"))\n",
    "CNN.add(BatchNormalization(axis=chanDim))\n",
    "CNN.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "CNN.add(Activation(\"relu\"))\n",
    "CNN.add(BatchNormalization(axis=chanDim))\n",
    "CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN.add(Dropout(0.25))\n",
    "# FC => RELU layers\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(512))\n",
    "CNN.add(Activation(\"relu\"))\n",
    "CNN.add(BatchNormalization())\n",
    "CNN.add(Dropout(0.5))\n",
    "# softmax classifier\n",
    "CNN.add(Dense(output_size))\n",
    "CNN.add(Activation(\"softmax\"))\n",
    "opt = optimizers.SGD( lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "CNN.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "numOfEpochs = 1\n",
    "modelBatchSize = 200\n",
    "history = CNN.fit( recreateImages(MNIST_training_X), MNIST_training_T, validation_data=(recreateImages(MNIST_validation_X), MNIST_validation_T), epochs=numOfEpochs, batch_size=modelBatchSize)\n",
    "\n",
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n",
    "\n",
    "MNIST_training_Err = history.history['loss'][len(history.history['loss'])-1]\n",
    "MNIST_training_AS = history.history['acc'][len(history.history['acc'])-1] * 100\n",
    "print(\"MNIST_training_Err = \"+str(MNIST_training_Err))\n",
    "print(\"MNIST_training_AS = \"+str(MNIST_training_AS))\n",
    "\n",
    "MNIST_validation_Err = history.history['val_loss'][len(history.history['val_loss'])-1]\n",
    "MNIST_validation_AS = history.history['acc'][len(history.history['acc'])-1] * 100\n",
    "print(\"MNIST_validation_Err = \"+str(MNIST_validation_Err))\n",
    "print(\"MNIST_validation_AS = \"+str(MNIST_validation_AS))\n",
    "\n",
    "MNIST_testing_Y = CNN.predict(recreateImages(MNIST_testing_X), batch_size=32)\n",
    "MNIST_testing_Err = RMS_error( MNIST_testing_T, MNIST_testing_Y )\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T, MNIST_testing_Y )\n",
    "print(\"MNIST_testing_Err = \"+str(MNIST_testing_Err))\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = CNN.predict(recreateImages(USPS_X), batch_size=32)\n",
    "USPS_Err = RMS_error( USPS_T, USPS_Y )\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T, USPS_Y )\n",
    "print(\"USPS_Err = \"+str(USPS_Err))\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))\n",
    "MNIST_Y4 = MNIST_testing_Y\n",
    "USPS_Y4 = USPS_Y\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#COMBINING THEM\n",
    "print(\"Combined Classification: \")\n",
    "MNIST_Y = []\n",
    "for y1, y2, y3, y4 in zip(MNIST_Y1, MNIST_Y2, MNIST_Y3, MNIST_Y4):\n",
    "    y1Class = np.argmax(y1)\n",
    "    y2Class = np.argmax(y2)\n",
    "    y3Class = np.argmax(y3)\n",
    "    y4Class = np.argmax(y4)\n",
    "    yClasses = np.array([ y1Class, y2Class, y3Class, y4Class ])\n",
    "    MNIST_Y.append( (stats.mode(yClasses))[0][0] )\n",
    "MNIST_Y = np.array(MNIST_Y)\n",
    "MNIST_testing_CM, MNIST_testing_AS = confusion_matrix( MNIST_testing_T0, MNIST_Y )\n",
    "print(\"MNIST_testing_CM = \"+str(MNIST_testing_CM))\n",
    "print(\"MNIST_testing_AS = \"+str(MNIST_testing_AS))\n",
    "\n",
    "USPS_Y = []\n",
    "for y1, y2, y3, y4 in zip(USPS_Y1, USPS_Y2, USPS_Y3, USPS_Y4):\n",
    "    y1Class = np.argmax(y1)\n",
    "    y2Class = np.argmax(y2)\n",
    "    y3Class = np.argmax(y3)\n",
    "    y4Class = np.argmax(y4)\n",
    "    yClasses = np.array([ y1Class, y2Class, y3Class, y4Class ])\n",
    "    USPS_Y.append( (stats.mode(yClasses))[0][0] )\n",
    "USPS_Y = np.array(USPS_Y)\n",
    "USPS_CM, USPS_AS = confusion_matrix( USPS_T0, USPS_Y )\n",
    "print(\"USPS_CM = \"+str(USPS_CM))\n",
    "print(\"USPS_AS = \"+str(USPS_AS))  \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
